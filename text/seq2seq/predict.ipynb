{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLACEHOLDER_FILE_PATH = \"../../datasets/poetry.txt\"\n",
    "PLACEHOLDER_MODEL_PATH = \"../models/seq2seq_poetry_model.h5\"\n",
    "PLACEHOLDER_ENCODER_MODEL_PATH = \"../models/seq2seq_poetry_encoder.h5\"\n",
    "PLACEHOLDER_DECODER_MODEL_PATH = \"../models/seq2seq_poetry_decoder.h5\"\n",
    "PLACEHOLDER_DICT_PATH = \"../models/seq2seq_poetry_dicts.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Init\n",
    "\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "with open(PLACEHOLDER_DICT_PATH, 'rb') as f:\n",
    "    tmp = pickle.load(f)\n",
    "    input_vocab = tmp[\"input_vocab\"]\n",
    "    target_vocab = tmp[\"target_vocab\"]\n",
    "    reverse_input_char_index = tmp[\"reverse_input_char_index\"]\n",
    "    reverse_target_char_index = tmp[\"reverse_target_char_index\"]\n",
    "    encoder_len = tmp[\"encoder_len\"]\n",
    "    decoder_len = tmp[\"decoder_len\"]\n",
    "    \n",
    "# 输入侧词汇表大小\n",
    "encoder_vocab_size = len(input_vocab)\n",
    "# 输出侧词汇表大小\n",
    "decoder_vocab_size = len(target_vocab)\n",
    "\n",
    "#model = load_model(PLACEHOLDER_MODEL_PATH)\n",
    "encoder_model = load_model(PLACEHOLDER_ENCODER_MODEL_PATH)\n",
    "decoder_model = load_model(PLACEHOLDER_DECODER_MODEL_PATH)\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "    # 先把上句输入编码器得到编码的中间向量，这个中间向量将是解码器的初始状态向量\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    # 初始的解码器输入是开始符'\\t'\n",
    "    target_seq = np.zeros((1, 1))\n",
    "    target_seq[0, 0] = target_vocab['\\t']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    # 迭代解码\n",
    "    while not stop_condition:\n",
    "        # 把当前的解码器输入和当前的解码器状态向量送进解码器\n",
    "        # 得到对下一个时刻的预测和新的解码器状态向量\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "        # 采样出概率最大的那个字作为下一个时刻的输入\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "        # 如果采样到了结束符或者生成的句子长度超过了decoder_len，就停止生成\n",
    "        if (sampled_char == '\\n' or len(decoded_sentence) > decoder_len):\n",
    "            stop_condition = True\n",
    "        # 否则我们更新下一个时刻的解码器输入和解码器状态向量\n",
    "        target_seq = np.zeros((1, 1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLACEHOLDER_START_TEXT = \"千山鸟飞绝\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run\n",
    "\n",
    "st = PLACEHOLDER_START_TEXT\n",
    "input_texts = [st]\n",
    "encoder_input_data = np.zeros((len(input_texts), encoder_len), dtype='int')\n",
    "\n",
    "for i, input_text in enumerate(input_texts):\n",
    "    for t, char in enumerate(input_text):\n",
    "        encoder_input_data[i, t] = (input_vocab[char] if char in input_vocab else random.randint(0, encoder_vocab_size-1))\n",
    "\n",
    "decoded_sentence = decode_sequence(encoder_input_data[0 : 1])\n",
    "decoded_sentence"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
